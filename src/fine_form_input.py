import sys
import os
import math
import re
from datetime import datetime
from enum import Enum
from argparse import ArgumentParser
import numpy as np
import pandas as pd
from typing import List, Tuple

import msvcrt

import cv2
import copy
import openpose_modules as op

#from fine_form_net import FineFormNet
#from fine_form_config import FineFormConfig

MSV_KEY_A = b'a'
MSV_KEY_C = b'c'
MSV_KEY_P = b'p'
MSV_KEY_E = b'e'
MSV_KEY_Q = b'q'
MSV_KEY_S = b's'
C = FineFormConfig()


class CaptureStatus(Enum):
    NO_FRAME = -1
    NOT_CAPTURED = 0
    CAPTURED = 1


def _op_empty() -> np.ndarray:
    d = np.zeros([18, 2])
    d[:] = np.nan
    return d


def _captured(stat: CaptureStatus):
    return stat == CaptureStatus.CAPTURED


def keypress_p():
    return msvcrt.getch() != MSV_KEY_P


def keypress_q():
    return msvcrt.getch() != MSV_KEY_Q


def until_quit_key():
    return not cv2.waitKey(1) == ord('q')


def _sys_exit_cause_camera_unused():
    print('ã‚«ãƒ¡ãƒ©ã¾ãŸã¯å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã¾ãŸã¯å‹•ç”»ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãŒå¯¾å¿œã—ã¦ã„ã¾ã›ã‚“')
    sys.exit(1)


def _cv2_destroy():
    try:
        cv2.destroyAllWindows()
    except RuntimeError as e:
        print(e)


def _start_video_capturing(path_or_device_id: int or str):
    cap = cv2.VideoCapture(path_or_device_id)
    cap.set(3, 640)
    cap.set(4, 480)
    # cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('H', '2', '6', '4'))

    if not cap.isOpened():
        _sys_exit_cause_camera_unused()

    _, frame = cap.read()
    if frame is None:
        _sys_exit_cause_camera_unused()

    h, w = frame.shape[:2]
    WIDTH = 320  # è§£æã«ååˆ†ãªã‚µã‚¤ã‚ºãŒã‚ã‚Œã°è‰¯ã„

    return cap, int(w * (WIDTH / w)), int(h * (WIDTH / w))


def _norm2d(p1, p2) -> float:
    """åº§æ¨™é–“ã®è·é›¢ï¼šX^2 + Y^2 = Z^2"""
    x1, y1 = p1
    x2, y2 = p2
    return math.sqrt((x1-x2)*(x1-x2) + (y1-y2)*(y1-y2))


class FormExtractor:
    """
    ãƒ•ã‚©ãƒ¼ãƒ æŠ½å‡ºå™¨

    å‹•ç”»ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ã‚«ãƒ¡ãƒ©ï¼‰ã‹ã‚‰ã‚¹ã‚¤ãƒ³ã‚°ã‚’æŠ½å‡ºã—ã€è§£æç”¨ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚
    ä¸€åº¦èª­ã¿è¾¼ã‚“ã å‹•ç”»ã¯quit_capturingã§ä¸­æ­¢ã™ã‚‹ã¾ã§å‡¦ç†ã‚’ç¶™ç¶šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

    Parameters:
        video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚ãªã‘ã‚Œã°ã‚«ãƒ¡ãƒ©èª­ã¿å–ã‚Šã€‚
        save_swing_frames: æŠ½å‡ºã—ãŸã‚¹ã‚¤ãƒ³ã‚°ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’ä¿å­˜ã™ã‚‹ã®ã§ã‚ã‚Œã°Trueã€‚
        skip_frames: ã‚¹ã‚¤ãƒ³ã‚°é–‹å§‹ã®æ¤œå‡ºé–“éš”(ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½)
    """

    def __init__(self, video_path: str = None, skip_frames: int = 8):
        self.__is_camera = video_path is None
        self.__path = video_path
        self.__skip_frames = skip_frames
        cap, w, h = _start_video_capturing(0 if self.__is_camera else self.__path)
        self.__cap = cap
        self.__width, self.__height = w, h
        self.__show_title = video_path
        self.__frame_count = 0
        self.__BASE_COUNT_THRES = 20
        self.__frame_count_thres = self.__BASE_COUNT_THRES

    def __exit__(self):
        self.quit_capturing()

    def quit_capturing(self):
        """
        èª­è¾¼ã¿ä¸­ã®ã‚«ãƒ¡ãƒ©ã¾ãŸã¯å‹•ç”»ã‚’ç ´æ£„ã™ã‚‹
        """
        _cv2_destroy()
        self.__cap.release()

    def capture_swing(self) -> Tuple[np.ndarray, np.ndarray, int]:
        """
        å‹•ç”»ã®ã‚¹ã‚¤ãƒ³ã‚°ã‚’æŠ½å‡ºã—ãƒ‡ãƒ¼ã‚¿åŒ–ã—ã¦è¿”å´ã™ã‚‹
        Returns:
            Tuple(s_data, s_frames, vsize)
            s_data: ã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
            s_frames: ã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ç”»åƒ
            vsize: èº«ä½“ã®ç¸¦ã‚µã‚¤ã‚ºãƒ»ãƒ”ã‚¯ã‚»ãƒ«å˜ä½
            success: å–å¾—å¯å¦
        """
        def __failure_result():
            return np.array([]), np.array([])

        self.__frame_count_thres += 20
        print('ã‚¹ã‚¤ãƒ³ã‚°é–‹å§‹ã‚’æ¤œå‡ºã—ã¾ã™\nå…¨ä½“ãŒæ˜ ã‚‹ã‚ˆã†ã«æ§‹ãˆã¦ãã ã•ã„')
        cap_stat, vsize = self.__progress_frame_to_swing_start()

        if _captured(cap_stat):
            print('ã‚¹ã‚¤ãƒ³ã‚°ã—ã¦ãã ã•ã„\n(Q:èª­è¾¼ã¿ä¸­æ–­)')
            frames, cap_stat = self.__read_entire_swing(vsize)
            print('frame len', len(frames))
        else:
            print('ã‚¹ã‚¤ãƒ³ã‚°é–‹å§‹ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ')
            frames = np.array([])

        if _captured(cap_stat) and len(frames) > C.input_sequence_len:
            print('æŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™')
            s_data, s_frames, cap_stat = self.__extract_batting_form_data(frames)
        elif _captured(cap_stat) and len(frames) <= C.input_sequence_len:
            print('ã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™')
            cap_stat = CaptureStatus.NOT_CAPTURED
        else:
            print('ã‚¹ã‚¤ãƒ³ã‚°çµ‚äº†ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ')

        if _captured(cap_stat):
            # èª­ã¿å–ã‚ŠãŒå®Œäº†ã™ã‚‹ã¾ã§ã¯æ¬¡ç¬¬ã«é•·ãèª­ã‚€
            # å®Œäº†ã—ãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
            self.__frame_count_thres = self.__BASE_COUNT_THRES
        else:
            print('æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ')
            s_data, s_frames = __failure_result()

        return s_data, s_frames, vsize, cap_stat

    def __cv2_imshow(self, img: np.ndarray, t=1):
        cv2.imshow(self.__show_title, img)
        cv2.waitKey(t)

    def __cap_back_frames(self, back: int = 20):
        self.__frame_count -= back
        self.__cap.set(cv2.CAP_PROP_POS_FRAMES, self.__frame_count)

    def __cap_read(self):
        ret, frame = self.__cap.read()
        self.__frame_count += 1
        if frame is not None:
            frame = cv2.resize(frame, dsize=(self.__width, self.__height))
        return ret, frame

    def __landmarks_is_swing_start(self, lm, lift_bat_thres=0.14):
        """å„éƒ¨ä½ã‹ã‚‰ã‚¹ã‚¤ãƒ³ã‚°é–‹å§‹ãƒ•ã‚©ãƒ¼ãƒ ã®åˆ¤å®šã‚’è¡Œã†"""
        head = lm[C.lg_head][0]
        legs = lm[C.lg_r_ankle][0]
        r_wrist, l_wrist = lm[C.lg_wrist]
        r_midhip, l_midhip = lm[C.lg_midhip]
        # éƒ¨ä½ã®ãƒ”ã‚¯ã‚»ãƒ«ä½ç½®ã‚’èº«ä½“ã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹æ¯”ç‡ã¨ã—ã¦ãƒ‡ãƒ¼ã‚¿åŒ–ã™ã‚‹
        # åŸºæº–ã¯é ­éƒ¨ã¨è„šéƒ¨ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°ã¨ã™ã‚‹
        vsize = float(abs(head[1] - legs[1]))
        _dist_wrists = _norm2d(r_wrist, l_wrist) / vsize
        _seal_other_hand = np.any(np.isnan([r_wrist, l_wrist])) and not np.all(np.isnan([r_wrist, l_wrist]))
        near_wrists = _dist_wrists < 0.4 or _seal_other_hand
        _finite_wrist = r_wrist if np.isfinite(r_wrist[1]) else l_wrist
        _dist_mh_wr = (r_midhip[1] - _finite_wrist[1]) / vsize
        rside_wr = head[0] > _finite_wrist[0]
        _dist_hd_wr = (_finite_wrist[1] - head[1]) / vsize
        vnear_head_wr = _dist_hd_wr < 0.24
        lift_bat = _dist_mh_wr > lift_bat_thres
        _dist_lr_mhi = (l_midhip[0] - r_midhip[0]) / vsize
        flat_mhi = _dist_lr_mhi > 0.12
        whole_body = np.all(np.isfinite(lm[C.lg_all_ff]))
        swing_start = near_wrists and rside_wr and vnear_head_wr and lift_bat and flat_mhi and whole_body
        print('S', swing_start, 'near-wr', f'{_dist_wrists:.3f}', near_wrists,
              'rside-wr', rside_wr,
              'vhead-wr', f'{_dist_hd_wr:.3f}', vnear_head_wr,
              'lift', f'{_dist_mh_wr:.3f}',
              'flat', f'{_dist_lr_mhi:.3f}',
              'in', whole_body)
        return swing_start, vsize

    def __landmarks_is_swing_end(self, lm, vsize):
        # å„éƒ¨ä½ã‹ã‚‰ã‚¹ã‚¤ãƒ³ã‚°çµ‚äº†ãƒ•ã‚©ãƒ¼ãƒ ã®åˆ¤å®š
        _, l_wrist = lm[C.lg_wrist]
        body, _, l_sholder = lm[C.lg_upper]
        _dist_bd_wr = _norm2d(body, l_wrist) / vsize
        far_body_wrist = _dist_bd_wr > 0.1
        _lside_wr = (l_wrist[0] - l_sholder[0]) / vsize
        leftside_wrist = _lside_wr > 0.1
        whole_body = np.all(np.isfinite(C.lg_all_ff))
        swing_end = far_body_wrist and leftside_wrist and whole_body
        print('E', swing_end, 'body-wrist', f'{_dist_bd_wr:.3f}',
              'lside-wrist(x)', f'{_lside_wr:.3f}',
              'in', whole_body)
        return swing_end

    def __progress_frame_to_swing_start(self) -> Tuple[bool, float]:
        """ã‚¹ã‚¤ãƒ³ã‚°é–‹å§‹ã¾ã§ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é€²ã‚ã‚‹"""
        frame_count = 0
        skip = self.__skip_frames
        lift_bat_thres = 0.1

        def _adjust_lift_thresholds():
            nonlocal lift_bat_thres
            if lift_bat_thres > 0.1:
                lift_bat_thres -= 0.01

        def _until_limit_camera_capturing():
            return not self.__is_camera or (self.__is_camera and frame_count < 500)

        vsize = -1
        cap_stat = CaptureStatus.NOT_CAPTURED
        while _until_limit_camera_capturing() and until_quit_key():
            _, frame = self.__cap_read()
            if frame is None:
                cap_stat = CaptureStatus.NO_FRAME
                break
            frame_count += 1
            if frame_count % skip != 0:
                continue
            candidate, subset = op.body_estimation(frame)
            # print('cnad', candidate)
            # print('subs', subset)
            if subset is None or len(subset) == 0:
                self.__cv2_imshow(frame)
                continue
            lm = extract_landmarks_or_nan(candidate, subset)
            # print('lmarks', lm)
            canvas = copy.deepcopy(frame)
            canvas = op.op_util.draw_bodypose(canvas, candidate, subset)
            self.__cv2_imshow(canvas)
            # cv2.imshow('Form Input', frame)
            is_start, vsize = self.__landmarks_is_swing_start(lm, lift_bat_thres)
            if is_start:
                print('ã‚¹ã‚¤ãƒ³ã‚°é–‹å§‹ã‚’æ¤œçŸ¥')
                cap_stat = CaptureStatus.CAPTURED
                break
            elif frame_count > 100:
                # æ¤œçŸ¥ãŒé…ã‘ã‚Œã°é–¾å€¤ã‚’ä¸‹ã’ã‚‹
                _adjust_lift_thresholds()

        return cap_stat, vsize

    def __read_entire_swing(self, vsize: float):
        """ã‚¹ã‚¤ãƒ³ã‚°å…¨ä½“ã‚’èª­ã¿ã“ã‚€ãƒ»çµ‚ç«¯ä½ç½®ã§åœæ­¢ãƒ»ä¸€å®šãƒ•ãƒ¬ãƒ¼ãƒ çµŒéã§å–ã‚Šç›´ã—"""
        frame_count = 0
        steps = C.step_swing_capturing

        if self.__is_camera:
            def _until_limit_camera_capturing():
                return frame_count < 500
        else:
            def _until_limit_camera_capturing():
                return True

        # XXX: ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãªãŒã‚‰å§¿å‹¢æ¨å®šã¯å‡¦ç†ãŒé‡ã„ã€‚æœ€åˆã¯å›ºå®šæ™‚é–“ã§å–å¾—ã—ã¦å¾Œã‹ã‚‰çµ‚äº†åˆ¤å®šãŒè‰¯ã„ã‹ã‚‚
        frames = []
        cap_stat = CaptureStatus.NOT_CAPTURED
        while _until_limit_camera_capturing() and until_quit_key():
            _, frame = self.__cap_read()
            if frame is None:
                cap_stat = CaptureStatus.NO_FRAME
                break
            frame_count += 1
            frames.append(frame)
            self.__cv2_imshow(frame)
            if frame_count % steps != 0:
                continue

            candidate, subset = op.body_estimation(frame)
            if len(subset) == 0:
                continue

            lm = extract_landmarks_or_nan(candidate, subset)
            is_end = self.__landmarks_is_swing_end(lm, vsize)
            if is_end:
                print('ã‚¹ã‚¤ãƒ³ã‚°çµ‚äº†')
                cap_stat = CaptureStatus.CAPTURED
                break
            elif not self.__is_camera and frame_count > self.__frame_count_thres:
                # å‹•ç”»ã§ã¯é–‹å§‹ãŒé…ã‚Œã‚‹å ´åˆãŒå¤šã„ã®ã§
                # é…ã‚ŒãŸå ´åˆã¯å°‘ã—æˆ»ã—ã¦å¤šã‚ã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–ã‚Šç›´ã™
                is_start, _ = self.__landmarks_is_swing_start(lm)
                if is_start:
                    print('é–‹å§‹ã‚’å†æ¤œå‡ºãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–ã‚Šç›´ã—ã¾ã™')
                    self.__cap_back_frames(self.__frame_count_thres / 2 + 8)  # 8=step
                    return np.array([]), CaptureStatus.NOT_CAPTURED

        if _captured(cap_stat):
            # æŒ¯ã‚Šçµ‚ã‚ã‚Šã®ãƒ•ã‚©ãƒ­ãƒ¼ã‚¹ãƒ«ãƒ¼ã‚’å¾—ã‚‹ãŸã‚
            # çµ‚äº†æ¤œçŸ¥ã¾ã§ã«ã‹ã‹ã£ãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã«å¿œã˜ã¦ä½™åˆ†ã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã‚€
            for _ in range(math.ceil(len(frames) / 20) + 2):
                _, frame = self.__cap_read()
                if frame is None:
                    break
                frames.append(frame)

        return np.array(frames), cap_stat

    def __extract_batting_form_data(self, frames: np.ndarray) -> np.ndarray:
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ•ã‚©ãƒ¼ãƒ ã‚’æŠ½å‡ºã™ã‚‹ã€‚

        Args:
            frames: ã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿åˆ— shape[L, ...Image_Shape] (L:å–å¾—ãƒ•ãƒ¬ãƒ¼ãƒ æ•°)
        Returns:
            ä»¥ä¸‹ã®Tupleã€‚(N:æŠ½å‡ºã‚¹ã‚¤ãƒ³ã‚°æ•°)
            * æŠ½å‡ºå¾Œã®ãƒ‡ãƒ¼ã‚¿ shape[N, 18, 2]
            * æŠ½å‡ºå¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ  shape[N, ...Image_Shape]
        """
        def __gain_body_data(s_idx: int):
            frame = frames[s_idx]
            candidate, subset = op.body_estimation(frame)
            return extract_landmarks_or_nan(candidate, subset), frame

        def __valid_ff_data(data: np.ndarray):
            return np.all(np.isfinite(data[C.lg_all_ff]))

        def __find_finite(s: int, e: int) -> Tuple[np.ndarray, np.ndarray]:
            for j in range(s, e):
                d, f = __gain_body_data(j)
                if d is not None and __valid_ff_data(d):
                    print('found')
                    return d, f
            print('not found')
            return None, None

        def __find_prev_finite(i: int) -> Tuple[np.ndarray, np.ndarray]:
            s = i - 3 if i - 3 >= 0 else 0
            print(f'find prev {s} to {i}')
            return __find_finite(s, i)

        def __find_next_finite(i: int) -> Tuple[np.ndarray, np.ndarray]:
            e = i + 3 if i + 3 < len(frames) else len(frames) - 1
            print(f'find next {e} to {i}')
            return __find_finite(i, e)

        s_data = []
        s_frames = []
        s_indices = slice_for_ff_input(frames)

        def __failure_result():
            return s_data, s_indices, CaptureStatus.NOT_CAPTURED

        print('sliced', s_indices.shape)
        if len(s_indices) != C.input_sequence_len + 1:
            print(f'warning: sliced data length is {len(s_indices)}, not {C.input_sequence_len + 1}')
            return __failure_result()

        # ç«¯ãƒ‡ãƒ¼ã‚¿ã«NaNãŒã‚ã‚‹ã¨æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿ã¨ã„ãˆãªã„ãŸã‚ã€å‘¨è¾ºã§å–ã‚Šç›´ã™
        s_idx_s, s_idx_e = s_indices[0], s_indices[-1]
        d0, f0 = __gain_body_data(s_idx_s)
        de, fe = __gain_body_data(s_idx_e)
        if d0 is None or not __valid_ff_data(d0):
            d, f = __find_prev_finite(s_idx_s)
            d0 = d0 if d is None else d
            f0 = f0 if f is None else f
        if de is None or not __valid_ff_data(de):
            d, f = __find_next_finite(s_idx_e)
            de = de if d is None else d
            fe = fe if f is None else f
        if d0 is None or de is None:
            return __failure_result()

        s_data.append(d0)
        s_frames.append(f0)
        for i in range(1, C.input_sequence_len):
            s_idx = s_indices[i]
            d, f = __gain_body_data(s_idx)
            if d is None:
                return __failure_result()
            s_data.append(d)
            s_frames.append(f)
        s_data.append(de)
        s_frames.append(fe)

        for f in s_frames:
            self.__cv2_imshow(f)

        return np.array(s_data), np.array(s_frames), CaptureStatus.CAPTURED


def slice_for_ff_input(frames: np.ndarray) -> List[int]:
    """
    ã‚¹ã‚¤ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¹ãƒ©ã‚¤ã‚·ãƒ³ã‚°
    åˆ¤å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å…¥åŠ›ç”¨ã«ã€å¹¾ã¤ã‹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é¸åˆ¥ã—ã¦å–å¾—ã™ã‚‹ã€‚
    ã‚¹ã‚¤ãƒ³ã‚°å¾ŒåŠã»ã©é€Ÿã„ã®ã§å–å¾—é–“éš”ã¯æ¼¸æ¬¡çš„ã«çŸ­ãã™ã‚‹ã€‚

    Returns:
        ã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ Shape[N + 1]
    """
    N = C.input_sequence_len
    base_skip = math.ceil(len(frames) / (N + 1))
    e_skip = math.ceil(base_skip / 8)  # æœ€å°1ã¯ç¢ºä¿

    skip = e_skip
    skip_inc = (base_skip - e_skip) / (N + 1)
    inc_coef = 1 / (N + 1)
    print(skip, skip_inc)

    # è¨ˆç®—ã®ã—ã‚„ã™ã•ã‹ã‚‰æœ«å°¾ã‹ã‚‰è¾¿ã‚‹
    # ã‚‚ã¨ã‚‚ã¨ã‚¹ã‚¤ãƒ³ã‚°çµ‚äº†å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚‚ä½™åˆ†ã«æ¸¡ã—ã¦ã‚ã‚‹æƒ³å®šãªã®ã§å°‘ã—ä½™ã—ã¦å–ã‚‹(èª¿æ•´å€¤ã¯çµŒé¨“å‰‡)
    index = math.floor(-0.1 * len(frames))
    s_frames_idx = []
    for i in range(N + 1):
        s_frames_idx.append(index)
        print(i, index, skip)
        skip += skip_inc * inc_coef * i
        index = index - math.floor(skip)

    # å¤–éƒ¨ã§ã®åˆ©ç”¨ã§ã¯æ­£æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã»ã†ãŒæ‰±ã„ã‚„ã™ã„ãŸã‚ç›´ã™
    return np.array([len(frames) + i for i in reversed(s_frames_idx)])


def nan_xy(): return np.array([np.nan, np.nan])


def extract_landmarks_or_nan(cand, subs) -> np.ndarray:
    """
    18å€‹ã®éƒ¨ä½ã«ã¤ã„ã¦ã€ã‚ã‚Œã°ãã®åº§æ¨™ã€ãªã‘ã‚Œã°NaNã§è¿”å´ã€‚
    è¤‡æ•°ã®æ¤œçŸ¥ãŒã‚ã£ãŸå ´åˆã€æœ€å¤§ã‚µã‚¤ã‚ºã®æ¤œå‡ºã‚’æ¡ç”¨ã™ã‚‹ã€‚

    Parameters:
        cand: OpenPoseã®è¿”å´å€¤ãƒ»å–å¾—ã§ããŸéƒ¨ä½ã®åº§æ¨™åŠã³ã‚¹ã‚³ã‚¢ã€‚
            Shape[N, 4] (N=æ¤œå‡ºã•ã‚ŒãŸéƒ¨ä½æ•°)
        subs: OpenPoseã®è¿”å´å€¤ãƒ»éƒ¨ä½ã®æ¤œå‡ºæœ‰ç„¡ã€‚æ¤œå‡ºã•ã‚ŒãŸå€‹ä½“ã®æ•°ãŒé•·ã•ã¨ãªã‚‹ã€‚
            Shape[D, 20] (D=æ¤œå‡ºã•ã‚ŒãŸå€‹ä½“æ•°, D<N, éƒ¨ä½ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹*18 + å…¨ä½“ã‚¹ã‚³ã‚¢*1 + å€‹ä½“æ¤œå‡ºä½ç½®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)
    Returns:
        æœ€å¤§ã‚µã‚¤ã‚ºã®éƒ¨ä½ãƒ‡ãƒ¼ã‚¿(1:é ­,2:é¦–,...)
        æœ€å¤§ã‚µã‚¤ã‚ºã¯é¼»(0)ã¨å³è¶³é¦–(10)ã®è·é›¢ã¨ã™ã‚‹ã€‚
        ndarray shape[18, 2]
        [
            [x1, y1],
            [x2, y2],
            ...
            [x18, y18],
        ]
    """
    if cand is None or subs is None or len(subs) == 0:
        return None
    h, l = C.lg_head[0], C.lg_leg[1]
    # æœ€å¤§ã‚µã‚¤ã‚ºã®subsetã‚’è¦‹ã¤ã‘ã‚‹
    max_i = np.argmax([abs(cand[int(s[h]), 1] - cand[int(s[l]), 1]) for s in subs])
    # subsetã®æŒ‡å®šã™ã‚‹candidateã®(x,y)ã‚’å–å¾—
    return np.array([cand[int(x), :2] if x != -1 else nan_xy() for x in subs[max_i, :18]])


def convert_landmarks_to_input_data(data: np.ndarray, vsize: float = None) -> np.ndarray:
    """
    èº«ä½“ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚©ãƒ¼ãƒ åˆ¤å®šå…¥åŠ›ã«å¤‰æ›
    èº«ä½“ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒ åˆ¤å®šå…¥åŠ›ã§ä½¿ç”¨ã™ã‚‹éƒ¨ä½ã®ã¿å–å¾—ã—ã€ç§»å‹•è·é›¢ã‚’ç§»å‹•æ¯”ç‡ã«å¤‰æ›ã™ã‚‹

    Parameters:
        data: Shape[N+1, 18, 2] ã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ»æ™‚ç³»åˆ—ã«ä¸¦ã‚“ã N+1å€‹ã®OpenPoseã®èº«ä½“éƒ¨ä½åº§æ¨™
            Nã¯ãƒ•ã‚©ãƒ¼ãƒ åˆ¤å®šå…¥åŠ›ã®æ™‚ç³»åˆ—ã‚µã‚¤ã‚ºã€‚
            å…ˆé ­ãƒ‡ãƒ¼ã‚¿ã¯åŸºæº–å€¤ã¨ã—ã¦ç”¨ã„ã‚‹ãŸã‚ã€å¤‰æ›å¾Œã®å€¤ã‹ã‚‰ã¯é™¤å¤–ã•ã‚Œã‚‹ã€‚
        vsize: (Optional)é ­éƒ¨(é¼»)ã¨è¶³é¦–ã®é–“ã®yè»¸æ–¹å‘ãƒ”ã‚¯ã‚»ãƒ«æ•°ã€‚ãªã‘ã‚Œã°0ç•ªç›®ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰èª­ã¿å–ã‚‹ã€‚
    Returns:
        å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿: Shape[N*P*2] åˆ¤å®šã§ç”¨ã„ã‚‹éƒ¨ä½ã®ç§»å‹•æ¯”ç‡(P:åˆ¤å®šéƒ¨ä½ã®å€‹æ•°)
            ä½†ã—ãƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ€§ãŒå¿…è¦ãªãŸã‚ã€å…ˆé ­ãƒ‡ãƒ¼ã‚¿ã«é¼»ã¨è¶³ãŒå«ã¾ã‚Œã¦ã„ãªã‘ã‚Œã°Noneã‚’è¿”ã™ã€‚
    """
    # assert np.all(np.isfinite(data[0, C.lg_vbody])), f'å…ˆé ­ãƒ‡ãƒ¼ã‚¿ã®é¼»ã¨å³è¶³é¦–ãŒæœªæ¤œå‡ºã§ã™, data={data}'
    if not np.all(np.isfinite(data[0, C.lg_vbody])):
        return None

    if vsize is None:
        nose, rakl = data[0, C.lg_vbody]
        vsize = abs(nose[1] - rakl[1])

    # ãƒ•ã‚©ãƒ¼ãƒ åˆ¤å®šã§ä½¿ç”¨ã™ã‚‹ç®‡æ‰€ã‚’æŠ½å‡º
    s_data = copy.deepcopy(data)[:, C.lg_all_ff]
    # åŸºæº–ä½ç½®ã‚’0ã¨ã—ã¦åŸºæº–ä½ç½®ã‹ã‚‰ã®ç§»å‹•è·é›¢ã«ç›´ã™
    # å…ˆé ­ãƒ‡ãƒ¼ã‚¿ã¯åŸºæº–ä½ç½®(ã™ã¹ã¦0)ãªã®ã§é™¤å¤–
    s_data = s_data[1:] - s_data[0, :]
    # ç§»å‹•è·é›¢ã‚’ã€èº«ä½“ã®ç¸¦ã‚µã‚¤ã‚ºã¨ã®ç§»å‹•æ¯”ç‡ã«å¤‰æ›
    s_data = s_data / vsize
    # æ¤œå‡ºã•ã‚Œãªã‹ã£ãŸéƒ¨ä½ã®å€¤NaNã‚’è£œé–“ã™ã‚‹
    # é–“ã®NaNã¯ä¸­é–“å€¤ã§ã€ç«¯ã®NaNã¯éš£æ¥å€¤ã§åŸ‹ã‚ã‚‹
    s_data = s_data.reshape([s_data.shape[0], math.prod(s_data.shape[1:])])
    s_data = interpolate_points(s_data)
    # å…¥åŠ›ã‚µã‚¤ã‚º = æ™‚ç³»åˆ—é•· * ä½¿ç”¨éƒ¨ä½ * 2
    return s_data.reshape(-1)


def interpolate_points(points: np.ndarray) -> np.ndarray:
    """åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’è£œé–“ãƒ»NaNã®ä»£æ›¿å€¤ã‚’åŸ‹ã‚ã‚‹"""
    return pd.DataFrame(points).interpolate(limit_direction='forward').values


def frames_dir_to_input(file_path: os.PathLike):
    """
    ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰é †æ¬¡ç”»åƒã§å§¿å‹¢æ¨å®šã—ã€ãƒ•ã‚©ãƒ¼ãƒ åˆ¤å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹ã€‚

    Parameters:
        file_path: ãƒ‘ã‚¹(ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª)
    """
    N = C.input_sequence_len

    # ãƒ•ã‚¡ã‚¤ãƒ«ã¯è¾æ›¸é †ã«æ™‚ç³»åˆ—ã§ä¸¦ã‚“ã§ã„ã‚‹ã‚‚ã®ã¨ã™ã‚‹
    files = sorted(os.listdir(file_path))
    assert len(files) >= N + 1, f'ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {len(files)} < {N} + 1'

    # seq_len + 1 ã ã‘ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«ã™ã‚‹
    frames = [cv2.imread(os.path.join(file_path, f)) for f in files[:N+1]]
    data = collect_ff_points(frames, quiet=True)
    return convert_landmarks_to_input_data(data)


def collect_ff_points(frames: np.ndarray, quiet: bool = False) -> np.ndarray:
    """ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ã€ãƒ•ã‚©ãƒ¼ãƒ åˆ¤å®šã§ç”¨ã„ã‚‹éƒ¨ä½ã®ã€æ™‚ç³»åˆ—åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›"""
    N = C.input_sequence_len
    # éƒ¨ä½åº§æ¨™ã®æ ¼ç´å…ˆã‚’ä½œã£ã¦ãŠãã€‚æ¬ æå€¤ã‚’è£œé–“ã™ã‚‹ãŸã‚
    # åŸºæº–ãƒ‡ãƒ¼ã‚¿[0]ã¨æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿[1:seq_len+1]ãŒã‚ã‚‹ã®ã§ã€æ™‚ç³»åˆ—ã‚µã‚¤ã‚ºï¼‹ï¼‘
    data = np.empty([N + 1, len(C.lg_all_ff), 2])

    def __print_indetected(points):
        nans = np.argwhere(np.isnan(points))
        nans = np.unique(nans[:, 0]) if len(nans) > 0 else []
        if not quiet:
            print('no detected parts', C.get_labels(nans))

    for i, img in enumerate(frames):
        candidates, subset = op.body_estimation(img)
        if not quiet:
            print(f'body --- {i:02d} ---')
            # print('candidate', candidates)
            print('subset', subset)
        points = extract_landmarks_or_nan(candidates, subset)
        __print_indetected(points)
        data[i, :] = points[C.lg_all_ff]

    return data


def save_form_data(data_name: str, data: np.ndarray, frames: np.ndarray):
    save_images(f'../input_images/{data_name}', frames)
    save_swing_data(f'../data/input/{data_name}.csv', data)


def save_images(img_dir: str, images: np.ndarray):
    """ã‚¹ã‚¤ãƒ³ã‚°ç”»åƒã‚’ä¿å­˜"""
    os.makedirs(img_dir, exist_ok=True)
    for i, img in enumerate(images):
        cv2.imwrite(os.path.join(img_dir, f'{i:02d}.png'), img)
    print(f'ãƒ•ã‚©ãƒ¼ãƒ ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {img_dir}')


def save_swing_data(data_file: str, data: np.ndarray):
    """ã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿(OpenPoseã®18éƒ¨ä½x,y)ã‚’ä¿å­˜"""
    if len(data.shape) > 2:
        # ï¼“æ¬¡ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ã«ãªã£ã¦ã„ã‚‹å ´åˆè¡Œåˆ—ã«ç›´ã™
        data = data.reshape([data.shape[0], math.prod(data.shape[1:])])
    pd.DataFrame(data, columns=C.ALL_COLUMNS).to_csv(data_file, index=False)
    print(f'ãƒ•ã‚©ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {data_file}')


def append_ff_input(ff_input: np.ndarray, target_score: float):
    """åˆ¤å®šå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´CSVã«è¿½åŠ """
    with open(f'../data/train.csv', mode='a') as w:
        if ff_input is not None:
            w.write(','.join(np.char.mod('%.6f', ff_input)))
            w.write(f',{target_score}\n')


def run_input_module_main(video_path: str = None, target_score: int = 0, start: int = 0, auto: bool = False,
                          save_images: bool = False, skip_frames: int = 8,
                          analysis_proc = None) -> np.ndarray:
    """
    å…¥åŠ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¡ã‚¤ãƒ³å‡¦ç†
    * ã‚¹ã‚¤ãƒ³ã‚°èª­ã¿å–ã‚Š
    * ã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ä¿å­˜

    Parameters:
        video_path: å‹•ç”»ãƒ‘ã‚¹ã€‚ãªã‘ã‚Œã°ã‚«ãƒ¡ãƒ©èª­ã¿å–ã‚Š
        target_score: èª­ã¿å–ã£ãŸã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ä»˜ã‘ã‚‹ã‚¹ã‚³ã‚¢
        analysis_proc: èª­ã¿å–ã‚Šãƒ‡ãƒ¼ã‚¿ã®è§£æãƒ—ãƒ­ã‚»ã‚¹ã€‚ãªã‘ã‚Œã°ãƒ‡ãƒ¼ã‚¿èª­è¾¼ã¿ã®ã¿å®Ÿè¡Œã•ã‚Œã‚‹
    Returns:
        åˆ¤å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å…¥åŠ› Shape[280] æ™‚ç³»åˆ—æ¯ã®éƒ¨ä½ã®å¤‰åŒ–ç‡(10*14*2)
    """
    print(f'è§£æãƒ¢ãƒ¼ãƒ‰: {"ON" if analysis_proc is not None else "OFF"}')
    data_name = ''  # ãƒ‡ãƒ¼ã‚¿ä¿å­˜å
    img_id = start - 1

    # ãƒ•ã‚©ãƒ¼ãƒ æŠ½å‡ºå™¨ã¯ã‚«ãƒ¡ãƒ©ã¾ãŸã¯ä¸ãˆãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é€£ç¶šçš„ã«ãƒ•ã‚©ãƒ¼ãƒ ã‚’èª­ã¿å–ã‚‹
    ex = FormExtractor(video_path, skip_frames=skip_frames)

    if video_path is None:
        data_name = f'form_{datetime.now().strftime("%Y%m%d%H%M%S")}_{target_score}'

        def __run_capturing():
            print('ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã‚¹ã‚¤ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿ã¾ã™ğŸˆ©')
            print('\nã‚«ãƒ¡ãƒ©ã¯æ°´å¹³ã«ã—ã¦å…¨èº«ãŒæ˜ ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„')
            return __cap_form()
    else:
        data_name = re.split(r'[/\\]', video_path)[-1].split('.')[0]

        def __run_capturing():
            print('å‹•ç”»ã‹ã‚‰ã‚¹ã‚¤ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿ã¾ã™ğŸˆ©')
            return __cap_form()

    # ï¼‘å›åˆ†ã®ãƒ•ã‚©ãƒ¼ãƒ ãƒ»ã‚¹ã‚¤ãƒ³ã‚°èª­ã¿å–ã‚Š
    def __cap_form() -> np.ndarray:
        data, frames, vsize, cap_stat = ex.capture_swing()
        if _captured(cap_stat):
            return convert_landmarks_to_input_data(data, vsize), data, frames, cap_stat
        else:
            return None, None, None, cap_stat

    def __save_data(ff_input, s_data, s_frames, score=None):
        if ff_input is None or s_data is None:
            print('ã‚¹ã‚¤ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ä¿å­˜ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã™')
            return
        nonlocal img_id
        img_id += 1
        scr = '' if score is None or np.isnan(score) else f'_{score:.2f}'
        save_form_data(f'{data_name}{scr}_{img_id:04d}', s_data, s_frames)
        append_ff_input(ff_input, target_score)

    def __wait_action_and_continue(ff_input, s_data, s_frames):
        k = msvcrt.getch()
        score = None
        if k == MSV_KEY_A and analysis_proc is not None:
            score = analysis_proc(ff_input)
        if (k == MSV_KEY_E or k == MSV_KEY_S or k == MSV_KEY_A):
            __save_data(ff_input, s_data, s_frames, score=score)
        return not (k == MSV_KEY_Q or k == MSV_KEY_E)

    ff_input: np.ndarray = None

    while True:
        ff_input, s_data, s_frames, cap_stat = __run_capturing()
        if cap_stat == CaptureStatus.NO_FRAME:
            print('ãƒ•ãƒ¬ãƒ¼ãƒ çµ‚ç«¯ã§ã™')
            break

        if auto:
            if save_images:
                __save_data(ff_input, s_data, s_frames)
            continue

        print('æ¬¡ã®æ“ä½œã‚’ã—ã¦ãã ã•ã„\n (Q:ä¿å­˜ã›ãšçµ‚äº†, E:ä¿å­˜ã—ã¦çµ‚äº†, C:ä¿å­˜ã›ãšç¶šè¡Œ,\n  S:ä¿å­˜ã—ã¦ç¶šè¡Œ, A:åˆ¤å®šã—ã¦ç¶šè¡Œ)')
        if not __wait_action_and_continue(ff_input, s_data, s_frames):
            break

    if ff_input is not None:
        ff_input.put(-1, target_score)

    return ff_input


class InputModuleArgument:
    def __init__(self, parser: ArgumentParser):
        p = parser.parse_args()
        self.target_score = p.eval_score
        self.video_path = p.data
        self.skip = p.skip_frames
        self.start_num = p.start_num
        self.auto = p.auto
        self.save_images = p.save_images


def create_arguments() -> InputModuleArgument:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®ã‚³ãƒãƒ³ãƒ‰å¼•æ•°ã‚’å®šç¾©"""
    # py xxx.py -d aaa.mp4 -v 1 -s -a
    p = ArgumentParser()
    p.add_argument('--eval-score', '-v', required=True, type=int, default=0, help='ã“ã®å‹•ç”»ã«ä»˜ã‘ã‚‹ã‚¹ã‚³ã‚¢(0 | 1)')
    p.add_argument('--data', '-d', help='å…¥åŠ›å‹•ç”»ãƒ‘ã‚¹(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼›ã‚«ãƒ¡ãƒ©å…¥åŠ›)')
    p.add_argument('--skip-frames', '-f', type=int, default=15, help='é–‹å§‹åˆ¤å®šãƒ•ãƒ¬ãƒ¼ãƒ ã®å–å¾—é–“éš”(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:15)')
    p.add_argument('--start-num', '-n', type=int, default=0, help='ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åé€£ç•ªã®é–‹å§‹ç•ªå·(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:0é–‹å§‹)')
    p.add_argument('--auto', '-a', action='store_true', help='è‡ªå‹•å®Ÿè¡Œ(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:False)')
    p.add_argument('--save-images', '-s', action='store_true', help='è‡ªå‹•å®Ÿè¡Œæ™‚ã€ã‚¹ã‚¤ãƒ³ã‚°ç”»åƒã‚’ä¿å­˜(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ:False)')
    return InputModuleArgument(p)


if __name__ == '__main__':
    # os.makedirs(f'../data/input/', exist_ok=True)
    args = create_arguments()

    # å¼•æ•°ãŒã‚ã‚Œã°ãã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    if args.video_path is not None:
        path = args.video_path
        print(f'{path}ã®ç”»åƒã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™')
    else:
        path = None

    run_input_module_main(path, args.target_score, start=args.start_num, auto=args.auto,
                          save_images=args.save_images, skip_frames=args.skip)
    print('\nçµ‚äº†ã—ã¾ã™')
